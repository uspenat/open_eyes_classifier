{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "open_eyes_classifier_training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5d0nIhOk6nI",
        "outputId": "fcc8d95c-e9d2-4db3-9497-972bcab87d8b"
      },
      "source": [
        "import google.colab\n",
        "from pathlib import Path\n",
        "\n",
        "google.colab.drive.mount(\"/content/drive\")\n",
        "AUX_DATA_ROOT = Path(\"/content/drive/My Drive\")\n",
        "\n",
        "import zipfile\n",
        "with zipfile.ZipFile(AUX_DATA_ROOT / 'eye_openness_data/dataset_final.zip', 'r') as archive:\n",
        "    archive.extractall()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wscraZnmA1q"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import cv2\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "# from torch.optim.lr_scheduler import StepLR\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import torchvision.models as models\n",
        "\n",
        "from scipy.optimize import brentq\n",
        "from scipy.interpolate import interp1d\n",
        "from sklearn.metrics import roc_curve"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzWOy0GuoYQ9"
      },
      "source": [
        "def compute_eer(labels, scores):\n",
        "    \"\"\"Compute the Equal Error Rate (EER) from the predictions and scores.\n",
        "    Args:\n",
        "        labels (list[int]): values indicating whether the ground truth\n",
        "            value is positive (1) or negative (0).\n",
        "        scores (list[float]): the confidence of the prediction that the\n",
        "            given sample is a positive.\n",
        "    Return:\n",
        "        (float, thresh): the Equal Error Rate and the corresponding threshold\n",
        "    NOTES:\n",
        "       The EER corresponds to the point on the ROC curve that intersects\n",
        "       the line given by the equation 1 = FPR + TPR.\n",
        "       The implementation of the function was taken from here:\n",
        "       https://yangcha.github.io/EER-ROC/\n",
        "    \"\"\"\n",
        "    fpr, tpr, thresholds = roc_curve(labels, scores, pos_label=1)\n",
        "    eer = brentq(lambda x : 1. - x - interp1d(fpr, tpr)(x), 0., 1.)\n",
        "    thresh = interp1d(fpr, thresholds)(eer)\n",
        "    return eer, thresh"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mK4G9LIpeM8"
      },
      "source": [
        "def eval(model, loader, ckpt_path=False):\n",
        "    if ckpt_path:\n",
        "        model.load_state_dict(torch.load(ckpt_path))\n",
        "\n",
        "    val_loss = 0.0\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    val_labels = []\n",
        "    val_probs = []\n",
        "    model.eval()  \n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            inputs, labels = batch[0].to(device), batch[1].to(device)\n",
        "          \n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            probs = torch.softmax(outputs, dim=1)\n",
        "            preds = torch.argmax(probs, dim=1)\n",
        "            total += labels.size(0)\n",
        "            correct += (preds == labels).sum().item()\n",
        "\n",
        "            val_labels += labels.cpu().numpy().tolist()\n",
        "            val_probs += probs[:, 1].cpu().numpy().tolist()\n",
        "\n",
        "    eer, _ = compute_eer(val_labels, val_probs)\n",
        "\n",
        "    return val_loss, correct / total, eer\n",
        "\n",
        "def train(model, epoch_num, optimizer, ckpt_save_path):\n",
        "    print(criterion, optimizer)\n",
        "    min_val_eer = np.inf\n",
        "\n",
        "    for epoch in range(epoch_num):\n",
        "        train_loss = 0.0\n",
        "\n",
        "        for batch in train_loader:\n",
        "            inputs, labels = batch[0].to(device), batch[1].to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "            \n",
        "        val_loss, val_accuracy, val_eer = eval(model, val_loader)\n",
        "        test_loss, test_accuracy, test_eer = eval(model, test_loader)\n",
        "\n",
        "        print('\\033[1m' + f'Epoch {epoch}:' + '\\033[0m' + f' train loss = {train_loss:.4f}')\n",
        "        print(f'val loss = {val_loss:.4f}, val accuracy = {val_accuracy:.4f}, val eer = {val_eer:.4f}')\n",
        "        print(f'test loss = {test_loss:.4f}, test accuracy = {test_accuracy:.4f}, test eer = {test_eer:.4f}')\n",
        "\n",
        "        if (val_eer < min_val_eer) or (val_eer < .02):\n",
        "            min_val_eer = val_eer\n",
        "            torch.save(model.state_dict(), ckpt_save_path)\n",
        "            print(f'Saving new weights with current val loss = {val_loss:.4f}, val accuracy = {val_accuracy:.4f}, val eer = {val_eer:.4f}, test eer = {test_eer:.4f}')\n",
        "\n",
        "\n",
        "    return eer"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYX2VOdq4TD4"
      },
      "source": [
        "Удаление ненужных файлов '.ipynb_checkpoints' и '.DS_Store'\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynBMMJcytUmr"
      },
      "source": [
        "DATA_DIR = '/content/dataset_final/'"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVE_MEvgtHBO",
        "outputId": "161aaa7d-7d2f-4d34-e844-8890e6cf822b"
      },
      "source": [
        "print(os.listdir(DATA_DIR))\n",
        "os.rmdir(os.path.join(DATA_DIR, '.ipynb_checkpoints'))\n",
        "os.remove(os.path.join(DATA_DIR, '.DS_Store'))\n",
        "\n",
        "for mode in ['train', 'val', 'test']:\n",
        "    path = os.path.join(DATA_DIR, mode)\n",
        "    print(os.listdir(path))\n",
        "    try:\n",
        "        os.rmdir(os.path.join(path, '.ipynb_checkpoints'))\n",
        "    except:\n",
        "        print('.ipynb_checkpoints file is already deleted')\n",
        "    try:\n",
        "        os.remove(os.path.join(path, '.DS_Store'))\n",
        "    except:\n",
        "        print('.DS_Store file is already deleted')\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['val', 'train', 'test']\n",
            "['closed', 'open']\n",
            ".ipynb_checkpoints file is already deleted\n",
            ".DS_Store file is already deleted\n",
            "['closed', 'open']\n",
            ".ipynb_checkpoints file is already deleted\n",
            ".DS_Store file is already deleted\n",
            "['closed', 'open']\n",
            ".ipynb_checkpoints file is already deleted\n",
            ".DS_Store file is already deleted\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRE0AZABoZ75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f468ffc1-adc5-4465-c156-9e03720e781c"
      },
      "source": [
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(256),\n",
        "    transforms.RandomHorizontalFlip(p=0.2),\n",
        "    transforms.RandomRotation(degrees=(-45, 45)),\n",
        "    transforms.RandomPerspective(distortion_scale=0.7, p=1, interpolation=2, fill=0),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.4976, 0.4976, 0.4976],\n",
        "                         std=[0.1970, 0.1970, 0.1970]),\n",
        "    ])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(256),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.4976, 0.4976, 0.4976],\n",
        "                          std=[0.1970, 0.1970, 0.1970])\n",
        "    ])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:716: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuqeLgwco8KI"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "train_dataset = torchvision.datasets.ImageFolder(root=os.path.join(DATA_DIR, 'train'), transform=train_transform)\n",
        "train_loader = DataLoader(train_dataset, \n",
        "                          batch_size=BATCH_SIZE, \n",
        "                          shuffle=True,  \n",
        "                          num_workers=0)\n",
        "\n",
        "val_dataset = torchvision.datasets.ImageFolder(root=os.path.join(DATA_DIR, 'val'), \n",
        "                                               transform=val_transform)\n",
        "val_loader = DataLoader(val_dataset, \n",
        "                        batch_size=BATCH_SIZE, \n",
        "                        shuffle=True, \n",
        "                        num_workers=0) \n",
        "\n",
        "test_dataset = torchvision.datasets.ImageFolder(root=os.path.join(DATA_DIR, 'test'), \n",
        "                                                transform=val_transform)\n",
        "test_loader = DataLoader(test_dataset, \n",
        "                         batch_size=BATCH_SIZE, \n",
        "                         shuffle=True, \n",
        "                         num_workers=0) "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1sw59EYsuSz",
        "outputId": "ea1348f4-c3bf-4dd3-d07b-a7cfec751ab2"
      },
      "source": [
        "train_dataset.find_classes(os.path.join(DATA_DIR, 'train'))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['closed', 'open'], {'closed': 0, 'open': 1})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kMGVT1zjrOVH",
        "outputId": "ca556295-cacd-4335-9a06-d0f011ed7662"
      },
      "source": [
        "model = models.wide_resnet50_2(pretrained=True)\n",
        "model.fc = nn.Linear(2048, 2)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), \n",
        "                      lr=0.0008, \n",
        "                      momentum=0.9, \n",
        "                      nesterov=True, \n",
        "                      weight_decay=0.002)\n",
        "\n",
        "_ = train(model, 80, optimizer, '/content/wide_resnet50_2.pth')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CrossEntropyLoss() SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    lr: 0.0008\n",
            "    momentum: 0.9\n",
            "    nesterov: True\n",
            "    weight_decay: 0.002\n",
            ")\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mEpoch 0:\u001b[0m train loss = 31.2839\n",
            "val loss = 2.7283, val accuracy = 0.9127, val eer = 0.0863\n",
            "test loss = 5.4325, test accuracy = 0.9137, test eer = 0.0699\n",
            "Saving new weights with current val loss = 2.7283, val accuracy = 0.9127, val eer = 0.0863, test eer = 0.0699\n",
            "\u001b[1mEpoch 1:\u001b[0m train loss = 12.0012\n",
            "val loss = 1.0023, val accuracy = 0.9401, val eer = 0.0457\n",
            "test loss = 1.7968, test accuracy = 0.9551, test eer = 0.0308\n",
            "Saving new weights with current val loss = 1.0023, val accuracy = 0.9401, val eer = 0.0457, test eer = 0.0308\n",
            "\u001b[1mEpoch 2:\u001b[0m train loss = 7.6901\n",
            "val loss = 0.7814, val accuracy = 0.9526, val eer = 0.0355\n",
            "test loss = 1.5704, test accuracy = 0.9586, test eer = 0.0379\n",
            "Saving new weights with current val loss = 0.7814, val accuracy = 0.9526, val eer = 0.0355, test eer = 0.0379\n",
            "\u001b[1mEpoch 3:\u001b[0m train loss = 5.9289\n",
            "val loss = 0.7285, val accuracy = 0.9626, val eer = 0.0254\n",
            "test loss = 1.4480, test accuracy = 0.9610, test eer = 0.0213\n",
            "Saving new weights with current val loss = 0.7285, val accuracy = 0.9626, val eer = 0.0254, test eer = 0.0213\n",
            "\u001b[1mEpoch 4:\u001b[0m train loss = 5.0175\n",
            "val loss = 1.9215, val accuracy = 0.8878, val eer = 0.0254\n",
            "test loss = 2.8067, test accuracy = 0.9243, test eer = 0.0319\n",
            "Saving new weights with current val loss = 1.9215, val accuracy = 0.8878, val eer = 0.0254, test eer = 0.0319\n",
            "\u001b[1mEpoch 5:\u001b[0m train loss = 5.0727\n",
            "val loss = 0.4586, val accuracy = 0.9800, val eer = 0.0305\n",
            "test loss = 1.0630, test accuracy = 0.9716, test eer = 0.0237\n",
            "\u001b[1mEpoch 6:\u001b[0m train loss = 3.7912\n",
            "val loss = 0.5050, val accuracy = 0.9726, val eer = 0.0254\n",
            "test loss = 0.9222, test accuracy = 0.9752, test eer = 0.0190\n",
            "\u001b[1mEpoch 7:\u001b[0m train loss = 3.2948\n",
            "val loss = 0.4860, val accuracy = 0.9751, val eer = 0.0305\n",
            "test loss = 1.0842, test accuracy = 0.9811, test eer = 0.0237\n",
            "\u001b[1mEpoch 8:\u001b[0m train loss = 2.9799\n",
            "val loss = 0.4435, val accuracy = 0.9726, val eer = 0.0203\n",
            "test loss = 1.3200, test accuracy = 0.9775, test eer = 0.0213\n",
            "Saving new weights with current val loss = 0.4435, val accuracy = 0.9726, val eer = 0.0203, test eer = 0.0213\n",
            "\u001b[1mEpoch 9:\u001b[0m train loss = 2.5384\n",
            "val loss = 0.4165, val accuracy = 0.9751, val eer = 0.0152\n",
            "test loss = 1.4239, test accuracy = 0.9752, test eer = 0.0223\n",
            "Saving new weights with current val loss = 0.4165, val accuracy = 0.9751, val eer = 0.0152, test eer = 0.0223\n",
            "\u001b[1mEpoch 10:\u001b[0m train loss = 3.0971\n",
            "val loss = 0.3187, val accuracy = 0.9825, val eer = 0.0203\n",
            "test loss = 1.1502, test accuracy = 0.9787, test eer = 0.0212\n",
            "\u001b[1mEpoch 11:\u001b[0m train loss = 2.7965\n",
            "val loss = 0.4046, val accuracy = 0.9825, val eer = 0.0254\n",
            "test loss = 1.0345, test accuracy = 0.9764, test eer = 0.0225\n",
            "\u001b[1mEpoch 12:\u001b[0m train loss = 2.2438\n",
            "val loss = 0.5142, val accuracy = 0.9576, val eer = 0.0343\n",
            "test loss = 1.3393, test accuracy = 0.9764, test eer = 0.0237\n",
            "\u001b[1mEpoch 13:\u001b[0m train loss = 2.2092\n",
            "val loss = 0.6472, val accuracy = 0.9526, val eer = 0.0254\n",
            "test loss = 1.4697, test accuracy = 0.9669, test eer = 0.0259\n",
            "\u001b[1mEpoch 14:\u001b[0m train loss = 2.1347\n",
            "val loss = 0.8487, val accuracy = 0.9476, val eer = 0.0305\n",
            "test loss = 1.5134, test accuracy = 0.9622, test eer = 0.0259\n",
            "\u001b[1mEpoch 15:\u001b[0m train loss = 1.8891\n",
            "val loss = 0.7553, val accuracy = 0.9751, val eer = 0.0196\n",
            "test loss = 1.5046, test accuracy = 0.9752, test eer = 0.0161\n",
            "Saving new weights with current val loss = 0.7553, val accuracy = 0.9751, val eer = 0.0196, test eer = 0.0161\n",
            "\u001b[1mEpoch 16:\u001b[0m train loss = 1.8336\n",
            "val loss = 0.5104, val accuracy = 0.9776, val eer = 0.0203\n",
            "test loss = 1.3970, test accuracy = 0.9681, test eer = 0.0237\n",
            "\u001b[1mEpoch 17:\u001b[0m train loss = 1.8064\n",
            "val loss = 0.6378, val accuracy = 0.9676, val eer = 0.0294\n",
            "test loss = 1.1096, test accuracy = 0.9775, test eer = 0.0213\n",
            "\u001b[1mEpoch 18:\u001b[0m train loss = 1.2460\n",
            "val loss = 0.4392, val accuracy = 0.9850, val eer = 0.0152\n",
            "test loss = 1.1204, test accuracy = 0.9835, test eer = 0.0154\n",
            "Saving new weights with current val loss = 0.4392, val accuracy = 0.9850, val eer = 0.0152, test eer = 0.0154\n",
            "\u001b[1mEpoch 19:\u001b[0m train loss = 1.0668\n",
            "val loss = 0.8917, val accuracy = 0.9776, val eer = 0.0254\n",
            "test loss = 1.5557, test accuracy = 0.9728, test eer = 0.0236\n",
            "\u001b[1mEpoch 20:\u001b[0m train loss = 1.1849\n",
            "val loss = 0.7613, val accuracy = 0.9626, val eer = 0.0392\n",
            "test loss = 2.0858, test accuracy = 0.9693, test eer = 0.0244\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-139990539237>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m                       weight_decay=0.002)\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/content/wide_resnet50_2.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-4-3f59fe05b092>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, epoch_num, optimizer, ckpt_save_path)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/sgd.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    115\u001b[0m                   \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                   \u001b[0mdampening\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdampening\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                   nesterov=nesterov)\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0;31m# update momentum_buffers in state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36msgd\u001b[0;34m(params, d_p_list, momentum_buffer_list, weight_decay, momentum, lr, dampening, nesterov)\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0md_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_p_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mweight_decay\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0md_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_p\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmomentum\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TlDjiouY97ws",
        "outputId": "be67eea4-eab2-45fe-f0bf-bd8fd557c475"
      },
      "source": [
        "eval(model, val_loader, 'wide_resnet50_2.pth')"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.5923457383178174, 0.9850374064837906, 0.015228426396226367)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNXfAUQy9qBj",
        "outputId": "bd5d3144-4d0f-4e4c-e6fc-4e311439d53b"
      },
      "source": [
        "eval(model, test_loader, 'wide_resnet50_2.pth')"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.1331980407703668, 0.983451536643026, 0.015366430259682356)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ee765jMcweG1"
      },
      "source": [
        "class OpenEyesClassificator:\n",
        "    def __init__(self, ckpt_path):\n",
        "        self.ckpt_path = ckpt_path\n",
        "        self.model = models.wide_resnet50_2()\n",
        "        self.model.fc = nn.Linear(2048, 2)\n",
        "        self.model.load_state_dict(torch.load(ckpt_path))\n",
        "        self.transform = transforms.Compose([\n",
        "                                             transforms.Resize(256),\n",
        "                                             transforms.CenterCrop(256),\n",
        "                                             transforms.ToTensor(),\n",
        "                                             transforms.Normalize(mean=[0.4976, 0.4976, 0.4976],\n",
        "                                                                  std=[0.1970, 0.1970, 0.1970])\n",
        "                                             ])\n",
        "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model.to(self.device)\n",
        "        self.model.eval()\n",
        "\n",
        "    def predict(self, inplm):\n",
        "        img = Image.open(inplm)\n",
        "        img = img.convert('RGB') # 3 channels needed for pretrained wideresnet weights usage \n",
        "        img = self.transform(img)\n",
        "        img = torch.unsqueeze(img, 0)\n",
        "        img = img.to(self.device)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            output = self.model(img)\n",
        "            probs = torch.softmax(output, dim=1)\n",
        "            is_open_score = probs[:, 1].cpu().numpy()\n",
        "            preds = torch.argmax(probs, dim=1)\n",
        "\n",
        "        return is_open_score"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaXYpruZb3BN"
      },
      "source": [
        "classifier = OpenEyesClassificator('wide_resnet50_2.pth')"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFbaCHUm9CjL",
        "outputId": "8d94c182-2c06-4207-b9a6-9f3cfb3a665f"
      },
      "source": [
        "path = '/content/dataset_final/val/closed/closed_102.jpg'\n",
        "classifier.predict(path)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.781304e-06], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqHGZO995ahq"
      },
      "source": [
        "path = '/content/dataset_final/val/open/open_197.jpg'\n",
        "classifier.predict(path)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}